{"tag":"Crawler","isDark":false,"type":"tag","path":"tags/Crawler/","json_base":"data/tags/Crawler/","json":"data/tags/Crawler/1.json","current":1,"total":1,"posts":[{"type":"post","json_base":"data/posts","json":"data/posts/2014/08/11/china-weather-radar-crawler.json","path":"2014/08/11/china-weather-radar-crawler/","data":{"title":"中国区气象雷达数据爬虫","content":"<p>作为一个数据控，爱好各种实时数据，比如中央气象台的<a href=\"http://www.nmc.gov.cn/publish/radar/stations-chongqing.htm\" target=\"_blank\" rel=\"external\">气象雷达</a>数据。最近在进行的一个HTML5项目，就是利用Canvas和WebGL，把外观土鳖的官方数据，变成洋气+实用的交互式地图。由于HTML5 Canvas CORS的限制，在没有服务器配合的情况下，无法跨域载入图片，然后<code>getImageData</code>，因此就做了一个爬虫。</p>\n<p>经过一番试验，发现国外的免费云服务只有GAE能够访问nmc.gov.cn，确定爬虫在GAE上安家了。大致计算了下数据量，全国167个雷达站，平均10分钟更新1帧，每帧是一幅约35KB的GIF图像，一天下来就至少800+M的数据，放GAE上不现实。同时前端也需要<code>.json</code>文件，描述雷达站信息以及数据帧列表，所以还需要数据库存储，而GAE坑爹的datastore quota，一天只能5w次读写，爬虫大概跑3圈就爆了。在这样一些约束下，最后脑洞大开的结合GitHub API，把数据全存到一个GitHub repository里，然后再把git tree拖回来当数据库用，解决问题。</p>\n<p>目前在GAE上部署了两个实例，分时运行，因为bandwidth quota大概只能支撑半天，然后每天删除repository重建一次，避免超过GitHub的quota。</p>\n<p>除了爬图片，地图叠加层的对其需要知道雷达站的坐标，以及数据的范围（即图片上的“数据范围：xxx km”），前者通过之前人肉爬到的一个包含全国雷达站坐标的xml文件解决问题。<br>至于数据范围没有找到官方的数据，最后写了一个简单的OCR算法直接从图片上识别。</p>\n<h2 id=\"u9644_u8BB0_uFF1A_u7528GitHub_API_u521B_u5EFAcommit_u6D41_u7A0B\"><a href=\"#u9644_u8BB0_uFF1A_u7528GitHub_API_u521B_u5EFAcommit_u6D41_u7A0B\" class=\"headerlink\" title=\"附记：用GitHub API创建commit流程\"></a>附记：用GitHub API创建commit流程</h2><p>GitHub提供了<a href=\"https://developer.github.com/v3/repos/contents/\" target=\"_blank\" rel=\"external\">Content API</a>，可以方便的对单个文件进行CRUD操作，每次操作产生1个commit。<br>如果需要一次commit多个文件（比如这个爬虫每次cron会新增数百文件），这样显然不实际。<br>更好的做法是通过<a href=\"https://developer.github.com/v3/git/\" target=\"_blank\" rel=\"external\">Git Data API</a>，模拟git创建一次commit的过程。<br>之前做git私有传输协议的经验立即发挥作，轻车熟路的解决，流程如下：</p>\n<ol>\n<li>用<a href=\"https://developer.github.com/v3/git/blobs/\" target=\"_blank\" rel=\"external\">Blob API</a>为每个文件创建一个blob</li>\n<li>用<a href=\"https://developer.github.com/v3/git/trees/\" target=\"_blank\" rel=\"external\">Tree API</a>为每个子文件夹创建一个tree，并添加其中文件对应的blob</li>\n<li>用<a href=\"https://developer.github.com/v3/git/commits/\" target=\"_blank\" rel=\"external\">Commit API</a>读出要commit分支最新的commit，以及commit对应的tree</li>\n<li>创建root tree，未改变的文件/文件夹需要原封不动的在tree里面保留，插入/替换新增的blob/tree</li>\n<li>创建commit，tree指向新的root tree，parent指向分支最新commit</li>\n<li>用<a href=\"https://developer.github.com/v3/git/refs/\" target=\"_blank\" rel=\"external\">Reference API</a>更新分支的ref，指向新创建的commit</li>\n</ol>\n<p>如果操作中断或重复操作，blob/tree都不会导致多余的数据产生（纯浪费上传带宽而已）。<br>因为git用SHA1 Digest作为所有git object的文件名，同内容的blob/tree不会重复。<br>需要注意一个例外，commit由于包含了时间戳，会重复创建。</p>\n<p>当然最好封装好的library，会省不少事。<br>比如我在这个项目里用到的python library是<a href=\"https://github.com/jacquev6/PyGithub\" target=\"_blank\" rel=\"external\">PyGitHub</a>，几个月前给这个项目发过pull request增加了些功能，比较熟悉用起来顺手。</p>\n<h2 id=\"u94FE_u63A5\"><a href=\"#u94FE_u63A5\" class=\"headerlink\" title=\"链接\"></a>链接</h2><ul>\n<li>源码: <a href=\"https://github.com/catx-weather/radar-bot\" target=\"_blank\" rel=\"external\">radar-bot</a></li>\n<li>爬到的数据：<a href=\"https://github.com/catx-weather/data\" target=\"_blank\" rel=\"external\">data</a></li>\n<li>OCR工具：<a href=\"https://github.com/catx-weather/frame-range-ocr\" target=\"_blank\" rel=\"external\">Frame Range OCR</a></li>\n</ul>\n","date":"2014-08-10T16:14:12.000Z","path":"2014/08/11/china-weather-radar-crawler/","isDark":false,"featureColor":"#caa084","featureImage":"/images/tornado.jpg","excerpt":"","featureSwatch":{"Vibrant":{"color":"#caa084","isDark":false,"contrast":2.3667779450941966},"Muted":{"color":"#785541","isDark":true,"contrast":9.562217921145681},"DarkVibrant":{"color":"#9c5c3d","isDark":true,"contrast":7.395012998220232},"DarkMuted":{"color":"#4b3a32","isDark":true,"contrast":15.322594218985449},"LightVibrant":{"color":"#d8bba5","isDark":false,"contrast":1.814844701319505},"LightMuted":{"color":"#dcd9d6","isDark":false,"contrast":1.4056903887271448}},"json":"data/posts/2014/08/11/china-weather-radar-crawler.json","tags":[{"name":"Crawler","slug":"Crawler","path":"tags/Crawler/","permalink":"http://catx.me/tags/Crawler/","postCount":1},{"name":"Fun","slug":"Fun","path":"tags/Fun/","permalink":"http://catx.me/tags/Fun/","postCount":2},{"name":"GAE","slug":"GAE","path":"tags/GAE/","permalink":"http://catx.me/tags/GAE/","postCount":1},{"name":"GitHub","slug":"GitHub","path":"tags/GitHub/","permalink":"http://catx.me/tags/GitHub/","postCount":6},{"name":"Python","slug":"Python","path":"tags/Python/","permalink":"http://catx.me/tags/Python/","postCount":1},{"name":"Weather","slug":"Weather","path":"tags/Weather/","permalink":"http://catx.me/tags/Weather/","postCount":1}],"categories":[{"name":"挨踢","slug":"挨踢","path":"categories/挨踢/","permalink":"http://catx.me/categories/挨踢/","postCount":17}]},"sha1":"782006404a88139474fb39bb6d391bdc181e5ead","isDigest":true}],"sha1":"db810e1f77bdbea5fdf78f2c39c142d13f3992a0"}